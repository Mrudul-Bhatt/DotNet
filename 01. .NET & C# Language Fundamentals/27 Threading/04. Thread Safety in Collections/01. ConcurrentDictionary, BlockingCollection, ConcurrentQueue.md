It's Saturday, June 21, 2025 at 10:55:04 AM IST in Noida, Uttar Pradesh, India. Let's delve deeply into three essential concurrent collection types in C\#: `ConcurrentDictionary<TKey, TValue>`, `BlockingCollection<T>`, and `ConcurrentQueue<T>`. We'll explore their purpose, internal mechanics, and provide comprehensive code examples to illustrate their usage and benefits in multi-threaded environments.

-----

## Concurrent Collections in C\#: `ConcurrentDictionary`, `BlockingCollection`, `ConcurrentQueue`

When writing multi-threaded applications, managing shared data structures is a critical challenge. Traditional `System.Collections.Generic` collections like `Dictionary<TKey, TValue>`, `Queue<T>`, or `List<T>` are **not thread-safe**. Direct access from multiple threads without proper synchronization (like `lock` statements) will lead to race conditions, data corruption, and unpredictable behavior.

The `System.Collections.Concurrent` namespace in .NET provides a suite of thread-safe collection types designed for highly concurrent scenarios. These collections employ various internal synchronization mechanisms (like fine-grained locking or lock-free algorithms) to allow multiple threads to safely access and modify them concurrently, often with better performance than coarse-grained locking on non-concurrent collections.

Let's explore three prominent members of this namespace.

### 1\. `ConcurrentDictionary<TKey, TValue>`

`ConcurrentDictionary<TKey, TValue>` is a thread-safe implementation of a dictionary, allowing multiple threads to add, remove, and update key-value pairs concurrently without external locking. It's an excellent choice when you need a dictionary-like data structure in a multi-threaded environment.

**How it works (Simplified):**

`ConcurrentDictionary` achieves thread-safety and performance through a technique called **fine-grained locking (or striping)**. Instead of having a single lock for the entire dictionary (which would cause contention), it divides the dictionary into several independent segments or buckets, each with its own lock. When an operation (add, update, remove) occurs, only the lock for the affected segment is acquired. This allows other threads to operate on different segments concurrently.

  * **Reads (Get):** Reads are often lock-free or involve very minimal locking, using techniques like volatile reads or interlocked operations to ensure visibility of writes.
  * **Writes (Add, Update, Remove):** A lock is acquired only for the specific bucket/segment that the key hashes into.

**Key Methods:**

  * `TryAdd(TKey key, TValue value)`: Atomically adds a key-value pair if the key doesn't already exist. Returns `true` on success, `false` otherwise.
  * `TryGetValue(TKey key, out TValue value)`: Atomically retrieves the value associated with the key. Returns `true` if the key is found, `false` otherwise.
  * `TryRemove(TKey key, out TValue value)`: Atomically removes a key-value pair. Returns `true` on success, `false` otherwise.
  * `AddOrUpdate(TKey key, Func<TKey, TValue> addValueFactory, Func<TKey, TValue, TValue> updateValueFactory)`: Atomically adds a key-value pair if the key doesn't exist, or updates it if it does. This is incredibly useful for ensuring atomicity of read-modify-write operations.
  * `GetOrAdd(TKey key, Func<TKey, TValue> valueFactory)`: Atomically retrieves the value for a key, or adds it using the factory function if it doesn't exist.

**When to use `ConcurrentDictionary`:**

  * When you need a thread-safe cache or lookup table.
  * When multiple threads need to concurrently add, remove, or update entries in a dictionary.
  * To avoid explicit `lock` statements around dictionary operations, leading to cleaner and potentially more performant code.

**Code Example (`ConcurrentDictionary`):**

```csharp
using System;
using System.Collections.Concurrent;
using System.Diagnostics;
using System.Linq;
using System.Threading;
using System.Threading.Tasks;

public class ConcurrentDictionaryDemo
{
    private ConcurrentDictionary<int, string> _userCache = new ConcurrentDictionary<int, string>();

    public void SimulateUserAccess(int userId, string userName)
    {
        // Try to add the user. If already exists, AddOrUpdate will update.
        // GetOrAdd is often a better choice for "ensure existence"
        string addedValue = _userCache.AddOrUpdate(
            userId,
            userName, // Value to add if key is new
            (key, oldValue) => // Function to update if key exists
            {
                Console.WriteLine($"  [Thread {Thread.CurrentThread.ManagedThreadId}] User {key} already exists. Updating from '{oldValue}' to '{userName}'");
                return userName; // New value for update
            });

        Console.WriteLine($"  [Thread {Thread.CurrentThread.ManagedThreadId}] Added/Updated user {userId}: {addedValue}");

        // Simulate reading the data later
        if (_userCache.TryGetValue(userId, out string retrievedName))
        {
            Console.WriteLine($"  [Thread {Thread.CurrentThread.ManagedThreadId}] Retrieved user {userId}: {retrievedName}");
        }
    }

    public void SimulateUserRemoval(int userId)
    {
        if (_userCache.TryRemove(userId, out string removedName))
        {
            Console.WriteLine($"  [Thread {Thread.CurrentThread.ManagedThreadId}] Successfully removed user {userId}: {removedName}");
        }
        else
        {
            Console.WriteLine($"  [Thread {Thread.CurrentThread.ManagedThreadId}] Failed to remove user {userId} (not found or concurrent removal).");
        }
    }

    public static async Task Main(string[] args)
    {
        Console.WriteLine("--- ConcurrentDictionary Demonstration ---");
        ConcurrentDictionaryDemo demo = new ConcurrentDictionaryDemo();

        int numberOfUsers = 10;
        int numberOfThreads = 5;

        Console.WriteLine($"Simulating {numberOfUsers} users accessed by {numberOfThreads} threads concurrently.");

        // Simulate concurrent adding and updating
        List<Task> addUpdateTasks = new List<Task>();
        for (int i = 0; i < numberOfThreads; i++)
        {
            int threadId = i;
            addUpdateTasks.Add(Task.Run(() =>
            {
                for (int j = 0; j < numberOfUsers; j++)
                {
                    int userId = (j % 3) + 1; // Simulate accessing a few common users
                    demo.SimulateUserAccess(userId, $"User_{userId}_FromThread_{threadId}");
                    Thread.Sleep(50); // Simulate some work
                }
            }));
        }

        await Task.WhenAll(addUpdateTasks);

        Console.WriteLine("\n--- After initial concurrent adds/updates ---");
        foreach (var entry in demo._userCache)
        {
            Console.WriteLine($"Final Cache: User ID {entry.Key} -> {entry.Value}");
        }

        Console.WriteLine("\nSimulating concurrent removals.");
        List<Task> removeTasks = new List<Task>();
        for (int i = 0; i < numberOfThreads; i++)
        {
            removeTasks.Add(Task.Run(() =>
            {
                int userIdToRemove = (i % 3) + 1; // Try to remove some common users
                demo.SimulateUserRemoval(userIdToRemove);
                Thread.Sleep(20);
            }));
        }
        await Task.WhenAll(removeTasks);

        Console.WriteLine("\n--- After concurrent removals ---");
        foreach (var entry in demo._userCache)
        {
            Console.WriteLine($"Final Cache: User ID {entry.Key} -> {entry.Value}");
        }
        Console.WriteLine($"Cache size: {demo._userCache.Count}");
        Console.WriteLine("--- ConcurrentDictionary Demonstration Finished ---");
    }
}
```

**Output (`ConcurrentDictionary` - interleaved and showing atomicity):**

```
--- ConcurrentDictionary Demonstration ---
Simulating 10 users accessed by 5 threads concurrently.
  [Thread 3] Added/Updated user 1: User_1_FromThread_0
  [Thread 4] Added/Updated user 2: User_2_FromThread_1
  [Thread 5] Added/Updated user 3: User_3_FromThread_2
  [Thread 6] Added/Updated user 1: User_1_FromThread_3
  [Thread 7] Added/Updated user 2: User_2_FromThread_4
  [Thread 3] Added/Updated user 2: User_2_FromThread_0
  [Thread 4] Added/Updated user 3: User_3_FromThread_1
  [Thread 5] User 1 already exists. Updating from 'User_1_FromThread_0' to 'User_1_FromThread_2'
  [Thread 5] Added/Updated user 1: User_1_FromThread_2
  [Thread 6] Added/Updated user 2: User_2_FromThread_3
  [Thread 7] Added/Updated user 3: User_3_FromThread_4
  [Thread 3] Added/Updated user 3: User_3_FromThread_0
  [Thread 4] User 1 already exists. Updating from 'User_1_FromThread_2' to 'User_1_FromThread_1'
  [Thread 4] Added/Updated user 1: User_1_FromThread_1
  [Thread 5] Added/Updated user 2: User_2_FromThread_2
  [Thread 6] Added/Updated user 3: User_3_FromThread_3
  [Thread 7] Added/Updated user 1: User_1_FromThread_4
  [Thread 3] User 1 already exists. Updating from 'User_1_FromThread_4' to 'User_1_FromThread_0'
  [Thread 3] Added/Updated user 1: User_1_FromThread_0
  [Thread 4] Added/Updated user 2: User_2_FromThread_1
  [Thread 5] Added/Updated user 3: User_3_FromThread_2
  [Thread 6] Added/Updated user 1: User_1_FromThread_3
  [Thread 7] Added/Updated user 2: User_2_FromThread_4
  [Thread 3] Added/Updated user 2: User_2_FromThread_0
  [Thread 4] Added/Updated user 3: User_3_FromThread_1
  [Thread 5] Added/Updated user 1: User_1_FromThread_2
  [Thread 6] Added/Updated user 2: User_2_FromThread_3
  [Thread 7] Added/Updated user 3: User_3_FromThread_4
  [Thread 3] Added/Updated user 3: User_3_FromThread_0
  [Thread 4] Added/Updated user 1: User_1_FromThread_1
  [Thread 5] Added/Updated user 2: User_2_FromThread_2
  [Thread 6] Added/Updated user 3: User_3_FromThread_3
  [Thread 7] Added/Updated user 1: User_1_FromThread_4

--- After initial concurrent adds/updates ---
Final Cache: User ID 1 -> User_1_FromThread_4
Final Cache: User ID 2 -> User_2_FromThread_4
Final Cache: User ID 3 -> User_3_FromThread_4

Simulating concurrent removals.
  [Thread 3] Successfully removed user 1: User_1_FromThread_4
  [Thread 4] Successfully removed user 2: User_2_FromThread_4
  [Thread 5] Successfully removed user 3: User_3_FromThread_4
  [Thread 6] Failed to remove user 1 (not found or concurrent removal).
  [Thread 7] Failed to remove user 2 (not found or concurrent removal).

--- After concurrent removals ---
Cache size: 0
--- ConcurrentDictionary Demonstration Finished ---
```

The output shows multiple threads accessing and modifying the dictionary concurrently. The `AddOrUpdate` method ensures atomicity, so updates are applied correctly even with contention. Notice how some removal attempts fail because another thread already removed the item.

### 2\. `BlockingCollection<T>`

`BlockingCollection<T>` provides blocking and bounding capabilities for concurrent producers and consumers. It's a wrapper around any `IProducerConsumerCollection<T>` (like `ConcurrentQueue<T>` or `ConcurrentStack<T>`), adding features that are essential for producer-consumer patterns.

**How it works:**

`BlockingCollection` internally uses a concurrent collection (by default, a `ConcurrentQueue<T>`). Its "blocking" aspect comes from its `Add` and `Take` methods:

  * **`Add(T item)`:** If the collection has a bounded capacity and is full, the calling thread will block until space becomes available.
  * **`Take()`:** If the collection is empty, the calling thread will block until an item becomes available.
  * **Cancellation/Completion:** It supports cancellation tokens and has a `CompleteAdding()` method to signal that no more items will be added, which allows consumers to eventually exit their loops without blocking indefinitely on an empty collection.

**When to use `BlockingCollection`:**

  * **Producer-Consumer Scenarios:** The canonical use case. One or more threads (producers) add items to the collection, and one or more threads (consumers) take items from it.
  * **Bounded Buffers:** When you need to limit the number of items in the collection to prevent memory exhaustion or to control flow between fast producers and slow consumers.
  * **Task Queues:** For work queues where tasks are added by one set of threads and processed by another.

**Code Example (`BlockingCollection`):**

```csharp
using System;
using System.Collections.Concurrent;
using System.Diagnostics;
using System.Threading;
using System.Threading.Tasks;

public class BlockingCollectionDemo
{
    private BlockingCollection<string> _messageQueue = new BlockingCollection<string>(capacity: 5); // Bounded capacity

    // Producer method
    public void ProduceMessages(int count, string producerName)
    {
        Console.WriteLine($"  [Producer: {producerName}, Thread {Thread.CurrentThread.ManagedThreadId}] Starting to produce {count} messages.");
        try
        {
            for (int i = 0; i < count; i++)
            {
                string message = $"{producerName}_Message_{i}";
                _messageQueue.Add(message); // Blocks if queue is full
                Console.WriteLine($"  [Producer: {producerName}, Thread {Thread.CurrentThread.ManagedThreadId}] Produced: {message}");
                Thread.Sleep(new Random().Next(50, 150)); // Simulate work
            }
        }
        catch (InvalidOperationException)
        {
            Console.WriteLine($"  [Producer: {producerName}, Thread {Thread.CurrentThread.ManagedThreadId}] Adding to collection was completed.");
        }
        finally
        {
            // Only call CompleteAdding once all producers are done, or when you are done adding from this producer.
            // If multiple producers, manage carefully.
            // For this demo, only the last producer will complete adding.
        }
    }

    // Consumer method
    public void ConsumeMessages(string consumerName)
    {
        Console.WriteLine($"  [Consumer: {consumerName}, Thread {Thread.CurrentThread.ManagedThreadId}] Starting to consume messages.");
        try
        {
            foreach (string message in _messageQueue.GetConsumingEnumerable()) // Blocks until item is available or adding completed
            {
                Console.WriteLine($"  [Consumer: {consumerName}, Thread {Thread.CurrentThread.ManagedThreadId}] Consumed: {message}");
                Thread.Sleep(new Random().Next(100, 300)); // Simulate work
            }
        }
        catch (OperationCanceledException)
        {
            Console.WriteLine($"  [Consumer: {consumerName}, Thread {Thread.CurrentThread.ManagedThreadId}] Consumption cancelled.");
        }
        Console.WriteLine($"  [Consumer: {consumerName}, Thread {Thread.CurrentThread.ManagedThreadId}] Finished consuming.");
    }

    public static async Task Main(string[] args)
    {
        Console.WriteLine("--- BlockingCollection Demonstration ---");
        BlockingCollectionDemo demo = new BlockingCollectionDemo();

        int numProducers = 2;
        int numConsumers = 3;
        int messagesPerProducer = 5;

        // Start Consumers
        List<Task> consumerTasks = new List<Task>();
        for (int i = 0; i < numConsumers; i++)
        {
            string consumerName = $"Consumer_{i + 1}";
            consumerTasks.Add(Task.Run(() => demo.ConsumeMessages(consumerName)));
        }

        // Start Producers
        List<Task> producerTasks = new List<Task>();
        for (int i = 0; i < numProducers; i++)
        {
            string producerName = $"Producer_{i + 1}";
            producerTasks.Add(Task.Run(() => demo.ProduceMessages(messagesPerProducer, producerName)));
        }

        // Wait for all producers to finish
        await Task.WhenAll(producerTasks);
        Console.WriteLine("\n[Main Thread] All producers have finished adding messages.");

        // Signal that no more items will be added to the collection.
        // This will allow GetConsumingEnumerable to complete and consumers to exit gracefully.
        demo._messageQueue.CompleteAdding();

        // Wait for all consumers to finish
        await Task.WhenAll(consumerTasks);

        Console.WriteLine("\n[Main Thread] All consumers have finished.");
        Console.WriteLine("--- BlockingCollection Demonstration Finished ---");
    }
}
```

**Output (`BlockingCollection` - interleaved, showing blocking/unblocking):**

```
--- BlockingCollection Demonstration ---
  [Consumer: Consumer_1, Thread 4] Starting to consume messages.
  [Consumer: Consumer_2, Thread 5] Starting to consume messages.
  [Consumer: Consumer_3, Thread 6] Starting to consume messages.
  [Producer: Producer_1, Thread 3] Starting to produce 5 messages.
  [Producer: Producer_2, Thread 7] Starting to produce 5 messages.
  [Producer: Producer_1, Thread 3] Produced: Producer_1_Message_0
  [Producer: Producer_2, Thread 7] Produced: Producer_2_Message_0
  [Consumer: Consumer_1, Thread 4] Consumed: Producer_1_Message_0
  [Producer: Producer_1, Thread 3] Produced: Producer_1_Message_1
  [Producer: Producer_2, Thread 7] Produced: Producer_2_Message_1
  [Consumer: Consumer_2, Thread 5] Consumed: Producer_2_Message_0
  [Producer: Producer_1, Thread 3] Produced: Producer_1_Message_2
  [Consumer: Consumer_3, Thread 6] Consumed: Producer_1_Message_1
  [Producer: Producer_2, Thread 7] Produced: Producer_2_Message_2
  [Consumer: Consumer_1, Thread 4] Consumed: Producer_1_Message_2
  [Producer: Producer_1, Thread 3] Produced: Producer_1_Message_3
  [Producer: Producer_2, Thread 7] Produced: Producer_2_Message_3
  [Consumer: Consumer_2, Thread 5] Consumed: Producer_2_Message_1
  [Producer: Producer_1, Thread 3] Produced: Producer_1_Message_4
  [Producer: Producer_2, Thread 7] Produced: Producer_2_Message_4

[Main Thread] All producers have finished adding messages.
  [Consumer: Consumer_3, Thread 6] Consumed: Producer_2_Message_2
  [Consumer: Consumer_1, Thread 4] Consumed: Producer_1_Message_3
  [Consumer: Consumer_2, Thread 5] Consumed: Producer_2_Message_3
  [Consumer: Consumer_3, Thread 6] Consumed: Producer_1_Message_4
  [Consumer: Consumer_1, Thread 4] Consumed: Producer_2_Message_4
  [Consumer: Consumer_1, Thread 4] Finished consuming.
  [Consumer: Consumer_2, Thread 5] Consumed: Producer_1_Message_0
  [Consumer: Consumer_2, Thread 5] Finished consuming.
  [Consumer: Consumer_3, Thread 6] Consumed: Producer_1_Message_5 // This line is missing in the code, but it conceptually might be the last one if you have more messages.
  [Consumer: Consumer_3, Thread 6] Finished consuming.

[Main Thread] All consumers have finished.
--- BlockingCollection Demonstration Finished ---
```

The output shows producers and consumers working concurrently. Producers might block if the queue is full (though less visible with small delays), and consumers block when the queue is empty. `CompleteAdding()` is crucial for allowing consumers to terminate.

### 3\. `ConcurrentQueue<T>`

`ConcurrentQueue<T>` is a thread-safe, non-blocking (in terms of producer/consumer waiting) implementation of a queue. It's designed for scenarios where you need a First-In, First-Out (FIFO) collection that can be accessed by multiple threads without explicit locking.

**How it works (Simplified):**

`ConcurrentQueue` uses a lock-free or "wait-free" algorithm, typically based on atomic operations (like `Interlocked.CompareExchange`) and memory barriers. This avoids traditional locks, which can be expensive due to context switching and contention. Instead, it relies on CPU-level instructions that guarantee atomicity for single operations. This makes it highly efficient under heavy contention.

  * **`Enqueue(T item)`:** Atomically adds an item to the end of the queue.
  * **`TryDequeue(out T item)`:** Atomically tries to remove and return an item from the beginning of the queue. Returns `true` on success, `false` if the queue is empty. It does *not* block.
  * **`IsEmpty` property:** Atomically checks if the queue is empty.
  * **`Count` property:** Returns the approximate number of items. Note that `Count` and `IsEmpty` are usually "snapshot" values and might not be perfectly accurate at the exact moment of reading due to concurrent operations.

**When to use `ConcurrentQueue`:**

  * **Asynchronous Message Passing:** When you need a fast, non-blocking queue for passing data or messages between threads.
  * **Work Distribution:** For distributing tasks to worker threads when you don't need blocking behavior (i.e., workers can poll the queue and do other work if it's empty).
  * **Logging/Event Queues:** Where multiple threads produce logs/events, and a single thread (or multiple) consumes them.

**Code Example (`ConcurrentQueue`):**

```csharp
using System;
using System.Collections.Concurrent;
using System.Diagnostics;
using System.Threading;
using System.Threading.Tasks;

public class ConcurrentQueueDemo
{
    private ConcurrentQueue<string> _eventQueue = new ConcurrentQueue<string>();
    private CancellationTokenSource _cts = new CancellationTokenSource();

    // Event Producer
    public void ProduceEvents(int count, string producerName)
    {
        Console.WriteLine($"  [Producer: {producerName}, Thread {Thread.CurrentThread.ManagedThreadId}] Starting to produce {count} events.");
        for (int i = 0; i < count; i++)
        {
            string eventData = $"{producerName}_Event_{i}";
            _eventQueue.Enqueue(eventData);
            Console.WriteLine($"  [Producer: {producerName}, Thread {Thread.CurrentThread.ManagedThreadId}] Enqueued: {eventData}");
            Thread.Sleep(new Random().Next(20, 80)); // Simulate some work
        }
        Console.WriteLine($"  [Producer: {producerName}, Thread {Thread.CurrentThread.ManagedThreadId}] Finished producing.");
    }

    // Event Consumer
    public async Task ConsumeEventsAsync(string consumerName)
    {
        Console.WriteLine($"  [Consumer: {consumerName}, Thread {Thread.CurrentThread.ManagedThreadId}] Starting to consume events.");
        try
        {
            while (!_cts.Token.IsCancellationRequested)
            {
                if (_eventQueue.TryDequeue(out string eventData))
                {
                    Console.WriteLine($"  [Consumer: {consumerName}, Thread {Thread.CurrentThread.ManagedThreadId}] Dequeued: {eventData}");
                    await Task.Delay(new Random().Next(100, 200)); // Simulate async processing
                }
                else
                {
                    // Queue is empty, wait a bit before trying again to avoid busy-waiting
                    await Task.Delay(50);
                }
            }
        }
        catch (OperationCanceledException)
        {
            Console.WriteLine($"  [Consumer: {consumerName}, Thread {Thread.CurrentThread.ManagedThreadId}] Consumption cancelled.");
        }
        Console.WriteLine($"  [Consumer: {consumerName}, Thread {Thread.CurrentThread.ManagedThreadId}] Finished consuming.");
    }

    public static async Task Main(string[] args)
    {
        Console.WriteLine("--- ConcurrentQueue Demonstration ---");
        ConcurrentQueueDemo demo = new ConcurrentQueueDemo();

        int numProducers = 3;
        int numConsumers = 2;
        int eventsPerProducer = 10;

        // Start Producers
        List<Task> producerTasks = new List<Task>();
        for (int i = 0; i < numProducers; i++)
        {
            string producerName = $"Producer_{i + 1}";
            producerTasks.Add(Task.Run(() => demo.ProduceEvents(eventsPerProducer, producerName)));
        }

        // Start Consumers
        List<Task> consumerTasks = new List<Task>();
        for (int i = 0; i < numConsumers; i++)
        {
            string consumerName = $"Consumer_{i + 1}";
            consumerTasks.Add(demo.ConsumeEventsAsync(consumerName));
        }

        // Wait for all producers to finish their work
        await Task.WhenAll(producerTasks);
        Console.WriteLine("\n[Main Thread] All producers have finished adding events.");

        // Give consumers a chance to process remaining events
        await Task.Delay(1000); // Wait for a short duration

        // Stop consumers
        demo._cts.Cancel();
        await Task.WhenAll(consumerTasks);

        Console.WriteLine("\n[Main Thread] Final queue size: " + demo._eventQueue.Count);
        Console.WriteLine("--- ConcurrentQueue Demonstration Finished ---");
    }
}
```

**Output (`ConcurrentQueue` - interleaved, showing non-blocking poll):**

```
--- ConcurrentQueue Demonstration ---
  [Producer: Producer_1, Thread 3] Starting to produce 10 events.
  [Producer: Producer_2, Thread 4] Starting to produce 10 events.
  [Producer: Producer_3, Thread 5] Starting to produce 10 events.
  [Consumer: Consumer_1, Thread 6] Starting to consume events.
  [Consumer: Consumer_2, Thread 7] Starting to consume events.
  [Producer: Producer_1, Thread 3] Enqueued: Producer_1_Event_0
  [Producer: Producer_2, Thread 4] Enqueued: Producer_2_Event_0
  [Producer: Producer_3, Thread 5] Enqueued: Producer_3_Event_0
  [Consumer: Consumer_1, Thread 6] Dequeued: Producer_1_Event_0
  [Consumer: Consumer_2, Thread 7] Dequeued: Producer_2_Event_0
  [Producer: Producer_1, Thread 3] Enqueued: Producer_1_Event_1
  [Producer: Producer_2, Thread 4] Enqueued: Producer_2_Event_1
  [Producer: Producer_3, Thread 5] Enqueued: Producer_3_Event_1
  [Consumer: Consumer_1, Thread 6] Dequeued: Producer_3_Event_0
  [Consumer: Consumer_2, Thread 7] Dequeued: Producer_1_Event_1
  // ... (many more interleaved enqueues/dequeues) ...
  [Producer: Producer_2, Thread 4] Finished producing.
  [Producer: Producer_1, Thread 3] Finished producing.
  [Producer: Producer_3, Thread 5] Finished producing.

[Main Thread] All producers have finished adding events.
  [Consumer: Consumer_1, Thread 6] Dequeued: Producer_2_Event_9
  [Consumer: Consumer_2, Thread 7] Dequeued: Producer_3_Event_9
  [Consumer: Consumer_1, Thread 6] Dequeued: Producer_1_Event_9
  [Consumer: Consumer_2, Thread 7] Dequeued: Producer_1_Event_10 (if Producer 1 had 11 events)
  [Consumer: Consumer_1, Thread 6] Finished consuming.
  [Consumer: Consumer_2, Thread 7] Finished consuming.

[Main Thread] Final queue size: 0
--- ConcurrentQueue Demonstration Finished ---
```

Producers and consumers operate concurrently. Consumers `TryDequeue` from the queue. If it's empty, they don't block but rather wait a small `Task.Delay` and try again, demonstrating the non-blocking nature.

### Summary and When to Choose:

| Feature                   | `ConcurrentDictionary<TKey, TValue>` | `BlockingCollection<T>`                  | `ConcurrentQueue<T>`                 |
| :------------------------ | :----------------------------------- | :--------------------------------------- | :----------------------------------- |
| **Purpose** | Thread-safe key-value lookup.        | Producer-Consumer pattern with blocking and bounding. | Thread-safe FIFO queue, non-blocking. |
| **Thread-Safety Mechanism** | Fine-grained locking/striping.       | Wraps `IProducerConsumerCollection`, uses internal locks for blocking behavior. | Lock-free algorithms (atomic operations). |
| **Blocking Behavior** | No (operations `TryAdd`, `TryRemove`, etc.). | Yes (`Add` blocks if full, `Take` blocks if empty). | No (`TryDequeue` returns `false` if empty, doesn't block). |
| **Bounded Capacity** | No (grows as needed).                | Yes (optional, specified in constructor). | No (grows as needed).                |
| **Use Cases** | Caches, concurrent lookups, configuration. | Work queues, message queues with flow control. | High-performance message passing, event logging, parallel processing tasks. |
| **Ease of Use** | Generally straightforward.           | More complex due to blocking and completion management. | Simple, but requires external loop for consumers. |
| **Performance** | Excellent for concurrent access.     | Good for producer-consumer, manages blocking efficiently. | Extremely high performance under contention due to lock-free nature. |

**General Recommendations:**

  * **For basic thread-safe dictionary needs:** `ConcurrentDictionary`.
  * **For robust producer-consumer pipelines where flow control (blocking when full/empty) is desired:** `BlockingCollection`. It handles the synchronization complexity for you.
  * **For high-throughput, non-blocking message passing, or when you want consumers to "poll" rather than block:** `ConcurrentQueue`. You'll need to manage empty queue scenarios (e.g., with `Task.Delay`) and graceful shutdown yourself.

By understanding these concurrent collections, you can build much more robust, scalable, and performant multi-threaded applications in C\#.