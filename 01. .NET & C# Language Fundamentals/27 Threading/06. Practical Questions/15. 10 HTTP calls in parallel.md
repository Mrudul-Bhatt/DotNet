It's Sunday, June 22, 2025 at 12:20:36 PM IST in Noida, Uttar Pradesh, India. Let's delve deeply into how to run 10 HTTP calls in parallel and wait for all to complete in .NET, focusing on the correct and efficient asynchronous approach.

-----

## Running 10 HTTP Calls in Parallel and Waiting for All to Complete in .NET

When you need to make multiple independent HTTP calls and wait for all of them to finish before proceeding, the **asynchronous programming model** with `async`/`await` and `Task.WhenAll()` is the highly recommended and most efficient approach in .NET.

### Why Asynchronous?

HTTP calls are inherently **I/O-bound** operations. This means that a significant portion of their execution time is spent waiting for data to travel over the network, for the server to process the request, and for the response to come back. During these waiting periods, a traditional synchronous approach would block the thread, rendering it idle and unproductive.

By using asynchronous operations:

  * **Non-blocking:** The thread making the HTTP request is released back to the Thread Pool (or UI context) while waiting for the network I/O to complete. This allows the thread to perform other useful work or process other requests.
  * **Scalability:** In server applications (like ASP.NET Core), this is crucial. You can handle many concurrent requests without exhausting your limited number of threads.
  * **Responsiveness:** In UI applications, it prevents the UI from freezing.

### The Solution: `HttpClient` + `Task.WhenAll()`

The combination of `HttpClient` for making HTTP requests and `Task.WhenAll()` for orchestrating concurrent tasks is the idiomatic and most effective way to achieve your goal.

**Key Components:**

1.  **`System.Net.Http.HttpClient`**: The modern, thread-safe (when used correctly) class for sending HTTP requests and receiving HTTP responses. You should generally use a *single, long-lived instance* of `HttpClient` throughout the lifetime of your application. Creating a new `HttpClient` for each request can lead to socket exhaustion.
2.  **`async`/`await`**: The core of asynchronous programming in C\#. It allows you to write non-blocking code that "awaits" the completion of an asynchronous operation without blocking the current thread.
3.  **`System.Threading.Tasks.Task.WhenAll()`**: As explained previously, this method takes a collection of `Task` objects and returns a single `Task` that completes when *all* of the input tasks have completed.

### Steps to Implement:

1.  **Prepare your `HttpClient`**: Instantiate a single `HttpClient` instance (preferably as a static or singleton).
2.  **Create a list of tasks**: For each HTTP call you want to make, create an `async` method (or an `async` lambda) that returns a `Task` (or `Task<TResult>`) representing that specific HTTP request. Add these tasks to a `List<Task<TResult>>`.
3.  **Use `Task.WhenAll()`**: Pass the list of tasks to `Task.WhenAll()`.
4.  **`await` the `Task.WhenAll()` result**: This will asynchronously wait for all HTTP calls to complete.
5.  **Process results/handle errors**: Once `Task.WhenAll()` completes, you can access the results of each individual call. Remember to handle potential exceptions, as `Task.WhenAll()` aggregates them into an `AggregateException`.

-----

### Code Example

Let's create a comprehensive example that simulates making multiple HTTP GET requests in parallel and processes their responses. We'll include error handling and demonstrate how to extract results.

```csharp
using System;
using System.Collections.Generic;
using System.Diagnostics;
using System.Linq;
using System.Net.Http;
using System.Threading.Tasks;

public class ParallelHttpCalls
{
    // Best practice: Use a single, static HttpClient instance for the application lifetime.
    // It is thread-safe for concurrent requests.
    private static readonly HttpClient _httpClient = new HttpClient();

    public static async Task Main(string[] args)
    {
        Console.WriteLine("--- Parallel HTTP Calls Demo ---");

        List<string> urls = new List<string>
        {
            "https://jsonplaceholder.typicode.com/todos/1",
            "https://jsonplaceholder.typicode.com/posts/2",
            "https://jsonplaceholder.typicode.com/users/3",
            "https://jsonplaceholder.typicode.com/comments/4",
            "https://jsonplaceholder.typicode.com/albums/5",
            "https://jsonplaceholder.typicode.com/photos/6",
            "https://jsonplaceholder.typicode.com/todos/7",
            "https://jsonplaceholder.typicode.com/posts/8",
            "https://jsonplaceholder.typicode.com/users/9",
            "https://jsonplaceholder.typicode.com/comments/10"
        };

        // Add a URL that will likely cause an error (e.g., 404 Not Found)
        urls.Add("https://jsonplaceholder.typicode.com/nonexistent/999");
        urls.Add("https://httpstat.us/500?sleep=100"); // Simulate a 500 error after a delay

        Stopwatch sw = Stopwatch.StartNew();

        // Step 1: Create a list of Task<string> for each HTTP GET request
        List<Task<string>> downloadTasks = new List<Task<string>>();
        foreach (string url in urls)
        {
            // HttpClient.GetStringAsync returns a Task<string> immediately.
            // The actual HTTP call starts here, but the current thread is not blocked.
            // We store the Task<string> in the list.
            Console.WriteLine($"  [Main] Starting download for: {url}");
            downloadTasks.Add(DownloadUrlContentAsync(url));
        }

        try
        {
            Console.WriteLine("\nWaiting for all HTTP calls to complete using Task.WhenAll()...");
            
            // Step 2: Use Task.WhenAll() to await the completion of all tasks concurrently.
            // This line asynchronously waits for all tasks in 'downloadTasks' to finish.
            // The result 'allContents' will be an array of strings, where each string is the content
            // from a successful download, in the same order as the 'urls' list.
            string[] allContents = await Task.WhenAll(downloadTasks);

            sw.Stop();
            Console.WriteLine($"\nAll {urls.Count} HTTP calls completed in {sw.ElapsedMilliseconds} ms.");
            Console.WriteLine("\n--- Successful Responses ---");

            // Step 3: Process the results of successful calls
            for (int i = 0; i < urls.Count; i++)
            {
                // This will only contain results from successfully completed tasks.
                // Tasks that faulted or were cancelled will cause Task.WhenAll to throw.
                string content = allContents[i]; 
                Console.WriteLine($"URL: {urls[i]}\nContent Length: {content.Length}\nContent Snippet: {content.Substring(0, Math.Min(100, content.Length))}\n---");
            }
        }
        catch (AggregateException ae)
        {
            // Step 4: Handle AggregateException for failed tasks
            sw.Stop();
            Console.ForegroundColor = ConsoleColor.Red;
            Console.WriteLine($"\nOne or more HTTP calls failed after {sw.ElapsedMilliseconds} ms:");
            foreach (var innerEx in ae.InnerExceptions)
            {
                if (innerEx is HttpRequestException httpEx)
                {
                    Console.WriteLine($"- HTTP Request Error: {httpEx.Message}. Status Code: {httpEx.StatusCode}");
                }
                else
                {
                    Console.WriteLine($"- General Error: {innerEx.GetType().Name}: {innerEx.Message}");
                }
            }
            Console.ResetColor();
        }
        catch (Exception ex)
        {
            // Catch any other unexpected exceptions
            sw.Stop();
            Console.ForegroundColor = ConsoleColor.Red;
            Console.WriteLine($"\nAn unexpected error occurred: {ex.Message}");
            Console.ResetColor();
        }
        finally
        {
            // _httpClient.Dispose(); // HttpClient should generally not be disposed if used as a static/singleton.
                                    // Let the application manage its lifecycle.
        }

        Console.WriteLine("\n--- Parallel HTTP Calls Demo Finished ---");
    }

    // A helper async method to encapsulate the HTTP call.
    // It's good practice to wrap HTTP calls in their own async methods for better error handling.
    private static async Task<string> DownloadUrlContentAsync(string url)
    {
        try
        {
            // GetStringAsync is a convenience method that returns string content.
            // It automatically handles disposing the HttpResponseMessage.
            // ConfigureAwait(false) is good practice for library methods like this,
            // as we don't need to resume on a specific SynchronizationContext.
            string content = await _httpClient.GetStringAsync(url).ConfigureAwait(false);
            return content;
        }
        catch (HttpRequestException ex)
        {
            Console.WriteLine($"  [Error] Failed to fetch {url}: {ex.Message}");
            // Re-throw the exception so Task.WhenAll can capture it.
            throw new HttpRequestException($"Failed to fetch {url}", ex, ex.StatusCode);
        }
        catch (Exception ex)
        {
            Console.WriteLine($"  [Error] An unexpected error occurred while fetching {url}: {ex.Message}");
            throw; // Re-throw other exceptions
        }
    }
}
```

**Typical Output:**

```
--- Parallel HTTP Calls Demo ---
  [Main] Starting download for: https://jsonplaceholder.typicode.com/todos/1
  [Main] Starting download for: https://jsonplaceholder.typicode.com/posts/2
  [Main] Starting download for: https://jsonplaceholder.typicode.com/users/3
  [Main] Starting download for: https://jsonplaceholder.typicode.com/comments/4
  [Main] Starting download for: https://jsonplaceholder.typicode.com/albums/5
  [Main] Starting download for: https://jsonplaceholder.typicode.com/photos/6
  [Main] Starting download for: https://jsonplaceholder.typicode.com/todos/7
  [Main] Starting download for: https://jsonplaceholder.typicode.com/posts/8
  [Main] Starting download for: https://jsonplaceholder.typicode.com/users/9
  [Main] Starting download for: https://jsonplaceholder.typicode.com/comments/10
  [Main] Starting download for: https://jsonplaceholder.typicode.com/nonexistent/999
  [Main] Starting download for: https://httpstat.us/500?sleep=100

Waiting for all HTTP calls to complete using Task.WhenAll()...
  [Error] Failed to fetch https://jsonplaceholder.typicode.com/nonexistent/999: Response status code does not indicate success: 404 (Not Found).
  [Error] Failed to fetch https://httpstat.us/500?sleep=100: Response status code does not indicate success: 500 (Internal Server Error).

One or more HTTP calls failed after ~200-300 ms: // Note: Total time is very fast!
- HTTP Request Error: Failed to fetch https://jsonplaceholder.typicode.com/nonexistent/999. Status Code: 404
- HTTP Request Error: Failed to fetch https://httpstat.us/500?sleep=100. Status Code: 500

--- Parallel HTTP Calls Demo Finished ---
```

**Explanation of Output and Efficiency:**

  * You'll notice that the "[Main] Starting download for..." messages appear almost instantly, demonstrating that the `DownloadUrlContentAsync` calls return `Task` objects immediately without blocking.
  * The "Waiting for all HTTP calls..." message then appears.
  * The total time elapsed will be very small (often under 500ms, depending on your internet connection), even though we made 12 HTTP requests. This is because they are executing **concurrently**. The program waits for the *slowest* request to complete, not the sum of all request times.
  * The error messages for the 404 and 500 status codes appear, demonstrating that `Task.WhenAll` successfully aggregated the `HttpRequestException` instances. If you want to continue processing successful results even if some fail, you'd need a different strategy (e.g., using `Task.WhenAll` on `Task<HttpResponseMessage>` and checking `IsSuccessStatusCode` individually, or `ContinueWith` on each task).

### Important Considerations:

  * **`HttpClient` Lifetime:** As demonstrated, use a single `static readonly HttpClient` instance. Each new `HttpClient` instance creates a new socket connection, which can lead to socket exhaustion under heavy load. If you cannot use a static instance (e.g., dependency injection in ASP.NET Core), use `IHttpClientFactory`.

  * **Error Handling with `Task.WhenAll`**: If *any* task passed to `Task.WhenAll` faults or is canceled, `Task.WhenAll` itself will fault (or be canceled). It collects all exceptions into an `AggregateException`. You must `catch (AggregateException ae)` to handle them.

  * **Partial Success**: If you want to know which tasks succeeded and which failed (and get their results/exceptions) without `Task.WhenAll` throwing an `AggregateException` immediately, you'd iterate through the list of `Task` objects *after* `await Task.WhenAll(tasks)`. Each `Task` will have its `Status` (e.g., `RanToCompletion`, `Faulted`, `Canceled`) and its `Exception` (if any).

    ```csharp
    // Modified catch block for partial success
    // after await Task.WhenAll(downloadTasks);
    // (This example shows how to get individual exceptions, but Task.WhenAll already aggregates)

    // For truly partial success without Task.WhenAll throwing:
    // await Task.WhenAll(downloadTasks.Select(task => task.ContinueWith(t => { /* handle success/failure of single task */ })));
    // Then iterate original tasks and check their status/result.
    // Example:
    // List<Task<string>> downloadTasks = urls.Select(url => DownloadUrlContentAsync(url)).ToList();
    // await Task.WhenAll(downloadTasks); // This line will still throw AggregateException if any fail.

    // To prevent Task.WhenAll from throwing and collect all results/exceptions:
    // This is a more advanced pattern if you truly need to process all results,
    // even from tasks that failed, without the outer Task.WhenAll throwing an exception.
    List<Task<Tuple<string, Exception>>> protectedTasks = new List<Task<Tuple<string, Exception>>>();
    foreach (string url in urls)
    {
        protectedTasks.Add(DownloadUrlContentAsync(url).ContinueWith(t => 
        {
            if (t.IsCompletedSuccessfully)
            {
                return Tuple.Create(t.Result, (Exception)null);
            }
            else if (t.IsFaulted)
            {
                return Tuple.Create((string)null, t.Exception.InnerException); // Get inner exception
            }
            else // t.IsCanceled
            {
                return Tuple.Create((string)null, (Exception)new OperationCanceledException());
            }
        }));
    }

    Tuple<string, Exception>[] resultsAndErrors = await Task.WhenAll(protectedTasks);

    Console.WriteLine("\n--- Results (including failures) ---");
    for (int i = 0; i < urls.Count; i++)
    {
        var item = resultsAndErrors[i];
        if (item.Item2 == null) // No exception
        {
            Console.WriteLine($"URL: {urls[i]} - SUCCESS. Content Length: {item.Item1.Length}");
        }
        else
        {
            Console.WriteLine($"URL: {urls[i]} - FAILED. Error: {item.Item2.Message}");
        }
    }
    ```

    This `ContinueWith` pattern is for advanced scenarios where you need to explicitly process every result and error without `Task.WhenAll` throwing.

By following this `HttpClient` and `Task.WhenAll()` pattern, you achieve efficient, scalable, and responsive parallel HTTP operations in your .NET applications.